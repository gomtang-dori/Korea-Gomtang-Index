name: Stocks Panel Mart (cache-based 1-file parquet + backfill status)

on:
  workflow_dispatch:
    inputs:
      sample_mode:
        description: "Sample mode for quick test (true/false)"
        type: string
        default: "false"
      sample_size:
        description: "Sample size when sample_mode=true"
        type: string
        default: "200"

      # panel build controls
      panel_start_date:
        description: "Panel start date (YYYY-MM-DD). Empty = no clamp"
        type: string
        default: ""
      panel_end_date:
        description: "Panel end date (YYYY-MM-DD). Empty = no clamp"
        type: string
        default: ""

      # DART standard summary controls
      dart_standard_full_from:
        description: "DART standard full-range year_from (YYYY)"
        type: string
        default: "2015"
      dart_standard_full_to:
        description: "DART standard full-range year_to (YYYY)"
        type: string
        default: "2026"

jobs:
  build_panel:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    env:
      PYTHONPATH: src
      # cache namespace (so you can reset cache by bumping this)
      STOCKS_PANEL_CACHE_NS: "v1"

      # NOTE: This workflow assumes raw/curated are provided via cache.
      # If cache is empty, curate/build_panel will still run, but coverage will be low.
      # (fetch_prices / fetch_krx_flows / fetch_fundamentals should be handled by a separate daily job.)
      # listings
      
      SAMPLE_MODE: ${{ inputs.sample_mode }}
      SAMPLE_SIZE: ${{ inputs.sample_size }}

      # DART curate -> full-range standard csv
      DART_STANDARD_FULL_RANGE: "true"
      DART_STANDARD_FULL_YEAR_FROM: ${{ inputs.dart_standard_full_from }}
      DART_STANDARD_FULL_YEAR_TO: ${{ inputs.dart_standard_full_to }}

      # panel clamp
      PANEL_START_DATE: ${{ inputs.panel_start_date }}
      PANEL_END_DATE: ${{ inputs.panel_end_date }}

      # output paths
      PANEL_OUT_PARQUET: data/stocks/mart/panel_daily.parquet
      BACKFILL_STATUS_CSV: docs/stocks/backfill_status.csv
      BACKFILL_STATUS_MD: docs/stocks/backfill_status.md

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install --quiet --no-input -U pip
          # minimal deps for this workflow + tabulate (required by pandas.to_markdown)
          pip install --quiet --no-input pandas pyarrow requests pykrx tabulate
          python -c "import tabulate; print('tabulate=', tabulate.__version__)"

      - name: Restore cache (raw + curated)
        id: cache_restore
        uses: actions/cache/restore@v4
        with:
          path: |
            data/stocks/raw/prices
            data/stocks/raw/krx_flows
            data/stocks/raw/fundamentals
            data/stocks/curated
          key: stocks-panel-mart-${{ env.STOCKS_PANEL_CACHE_NS }}-${{ github.ref_name }}-${{ github.run_id }}
          restore-keys: |
            stocks-panel-mart-${{ env.STOCKS_PANEL_CACHE_NS }}-${{ github.ref_name }}-
            stocks-panel-mart-${{ env.STOCKS_PANEL_CACHE_NS }}-

      - name: Cache precheck summary (raw/curated coverage)
        if: always()
        run: |
          echo "[cache] hit? -> ${{ steps.cache_restore.outputs.cache-hit }}"
          python - <<'PY'
          from pathlib import Path
          def count_files(p: Path, suffix: str):
            if not p.exists():
              return 0
            return sum(1 for x in p.rglob(f"*{suffix}") if x.is_file())

          prices = Path("data/stocks/raw/prices")
          flows  = Path("data/stocks/raw/krx_flows")
          fund   = Path("data/stocks/raw/fundamentals")
          curated= Path("data/stocks/curated")

          print("[precheck] prices_csv_files =", count_files(prices, ".csv"))
          print("[precheck] flows_parquet_files =", count_files(flows, ".parquet"))
          print("[precheck] fundamentals_parquet_files =", count_files(fund, ".parquet"))
          # curated has nested ticker folders; just show whether folder exists + a few counts
          print("[precheck] curated_exists =", curated.exists())
          if curated.exists():
            # sample counts
            print("[precheck] curated_flows_daily_parquet =", count_files(curated, "flows_daily.parquet"))
            print("[precheck] curated_fund_daily_parquet =", count_files(curated, "fundamentals_daily.parquet"))
          PY
          
      - name: Restore stocks raw/curated cache
        uses: actions/cache/restore@v4
        with:
          path: |
            data/stocks/raw/prices
            data/stocks/raw/krx_flows
            data/stocks/raw/fundamentals
            data/stocks/curated
          key: stocks-panel-mart-v1-${{ github.ref_name }}-${{ github.run_id }}
          restore-keys: |
            stocks-panel-mart-v1-${{ github.ref_name }}-
            stocks-panel-mart-v1-
          
      - name: Fetch listings (KOSPI+KOSDAQ)
        run: |
          python src/stocks/fetch_listings.py
          python - <<'PY'
          import pandas as pd
          df = pd.read_parquet("data/stocks/master/listings.parquet")
          print("[listings] rows=", len(df), "unique_tickers=", df["ticker"].astype(str).nunique())
          print(df.head(3).to_string(index=False))
          PY

      # (선택) prices/flows/fundamentals 수집 워크플로우가 별도로 존재한다면 여기서 호출하지 않고,
      # 이 워크플로우는 "cache 기반"으로 raw/curated를 사용해 panel + 리포트만 생성합니다.
      # cache가 비어있다면 curate/build_panel은 실행되지만 커버리지는 낮을 수 있습니다.      
      # 이미 raw/curated 가 존재(또는 cache restore)한다고 가정합니다.
      # 필요한 경우, 아래 3개 스텝을 별도 워크플로우(또는 이 워크플로우에 옵션으로) 추가하면 됩니다.
      # - python src/stocks/fetch_prices.py
      # - python src/stocks/fetch_krx_flows.py
      # - python src/stocks/fetch_fundamentals.py

      - name: Curate flows (raw -> curated)
        continue-on-error: true
        run: |
          python src/stocks/curate_flows.py || echo "⚠️ curate_flows error"

      - name: Curate fundamentals (raw -> curated)
        continue-on-error: true
        run: |
          python src/stocks/curate_fundamentals.py || echo "⚠️ curate_fundamentals error"

      - name: Curate DART (raw -> curated long + standard csv)
        continue-on-error: true
        run: |
          # curate_dart는 raw json cache가 있을 때만 의미가 있습니다.
          python src/stocks/curate_dart.py || echo "⚠️ curate_dart error"
          ls -lh docs/stocks/dart_standard_*.csv 2>/dev/null || true
          
      - name: Save stocks raw/curated cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            data/stocks/raw/prices
            data/stocks/raw/krx_flows
            data/stocks/raw/fundamentals
            data/stocks/curated
          key: stocks-panel-mart-v1-${{ github.ref_name }}-${{ github.run_id }}


      - name: Build merged 1-file panel parquet
        run: |
          python src/stocks/build_panel_merged.py
          ls -lh data/stocks/mart/panel_daily.parquet

      - name: Backfill status report (csv + md)
        run: |
          python src/stocks/report_backfill_status.py
          ls -lh docs/stocks/backfill_status.*

      - name: Save cache (raw + curated)
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            data/stocks/raw/prices
            data/stocks/raw/krx_flows
            data/stocks/raw/fundamentals
            data/stocks/curated
          key: stocks-panel-mart-${{ env.STOCKS_PANEL_CACHE_NS }}-${{ github.ref_name }}-${{ github.run_id }}

      - name: Upload panel + reports (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: stocks-panel-mart
          path: |
            data/stocks/mart/panel_daily.parquet
            docs/stocks/backfill_status.csv
            docs/stocks/backfill_status.md
          retention-days: 30
          if-no-files-found: warn
