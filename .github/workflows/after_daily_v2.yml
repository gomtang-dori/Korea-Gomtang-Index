name: daily_v2

on:
  workflow_dispatch:
    inputs:
      recent_days:
        description: "최근 N일만 갱신 (YYYYMMDD 범위 계산용). 기본 31"
        required: true
        default: "31"
  schedule:
    - cron: "15 1 * * 1-5"  # 평일 한국시간 오전 10:15 (UTC 01:15)

jobs:
  daily:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set date range (recent only)
        run: |
          END=$(date -u -d '1 day ago' +%Y%m%d)

          # workflow_dispatch면 inputs.recent_days 사용, schedule이면 기본 31
          RECENT_DAYS="${{ inputs.recent_days }}"
          if [ -z "$RECENT_DAYS" ]; then RECENT_DAYS="31"; fi

          START=$(date -u -d "$((RECENT_DAYS+0)) days ago" +%Y%m%d)

          echo "BACKFILL_END=$END" >> $GITHUB_ENV
          echo "BACKFILL_START=$START" >> $GITHUB_ENV
          echo "CACHE_BUFFER_DAYS=450" >> $GITHUB_ENV

          echo "[date_range] RECENT_DAYS=$RECENT_DAYS START=$START END=$END"

      # -------------------------
      # 데이터 수집 (Caches) - 최근구간만
      # -------------------------
      - name: Cache Rates 3Y Bundle (ECOS 817Y002) [KTB3Y + Corp AA-/BBB-]
        env:
          ECOS_KEY: ${{ secrets.ECOS_KEY }}
          BACKFILL_START: ${{ env.BACKFILL_START }}
          BACKFILL_END: ${{ env.BACKFILL_END }}
          CACHE_BUFFER_DAYS: ${{ env.CACHE_BUFFER_DAYS }}
          RATES_STAT_CODE: "817Y002"
          RATES_CYCLE: "D"
          ECOS_KTB3Y_ITEM_CODE1: "010200000"
          ECOS_CORP3Y_AA_ITEM_CODE1: "010300000"
          ECOS_CORP3Y_BBB_ITEM_CODE1: "010320000"
          RATES_3Y_BUNDLE_PATH: data/cache/rates_3y_bundle.parquet
        run: |
          set -e
          export PYTHONPATH=src
          python src/caches/cache_rates_3y_bundle_ecos.py

      - name: Cache F08 (Foreigner flow) [pykrx] KOSPI+KOSDAQ
        env:
          BACKFILL_START: ${{ env.BACKFILL_START }}
          BACKFILL_END: ${{ env.BACKFILL_END }}
          CACHE_BUFFER_DAYS: ${{ env.CACHE_BUFFER_DAYS }}
          F08_CACHE_PATH: data/cache/f08_foreigner_flow.parquet
        run: |
          set -e
          export PYTHONPATH=src
          python src/caches/cache_f08_foreigner_flow_pykrx.py

      - name: Cache F09 (Credit/Deposit) [data.go.kr]
        env:
          DATA_GO_KR_SERVICE_KEY: ${{ secrets.DATA_GO_KR_SERVICE_KEY }}
          BACKFILL_START: ${{ env.BACKFILL_START }}
          BACKFILL_END: ${{ env.BACKFILL_END }}
          CACHE_BUFFER_DAYS: ${{ env.CACHE_BUFFER_DAYS }}
          F09_CACHE_PATH: data/cache/f09_credit_deposit.parquet
        run: |
          set -e
          export PYTHONPATH=src
          python src/caches/cache_f09_credit_deposit_datago.py

      # ✅ (B) 추가: index_levels 캐시 (KOSPI/KOSDAQ/K200 close)
      # - 메인 리포트에서 KOSPI(raw)가 '-'로 뜨는 문제를 해결하려면,
      #   render_report.py가 merge하는 data/cache/index_levels.parquet가 최신이어야 함.
      - name: Cache index levels (FDR) [KOSPI/KOSDAQ/K200]
        env:
          BACKFILL_START: ${{ env.BACKFILL_START }}
          BACKFILL_END: ${{ env.BACKFILL_END }}
          CACHE_BUFFER_DAYS: ${{ env.CACHE_BUFFER_DAYS }}
          INDEX_LEVELS_CACHE_PATH: data/cache/index_levels.parquet
          K200_CACHE_PATH: data/cache/k200_close.parquet
          FDR_KOSPI_SYMBOL: "KS11"
          FDR_KOSDAQ_SYMBOL: "KQ11"
          FDR_K200_SYMBOL: "KS200"
        run: |
          set -e
          export PYTHONPATH=src
          python src/caches/cache_index_levels_fdr.py

      - name: Cache USD/KRW (ECOS)
        env:
          ECOS_KEY: ${{ secrets.ECOS_KEY }}
          ECOS_USDKRW_STAT_CODE: ${{ secrets.ECOS_USDKRW_STAT_CODE }}
          ECOS_USDKRW_ITEM_CODE1: ${{ secrets.ECOS_USDKRW_ITEM_CODE1 }}
        run: |
          set -e
          export PYTHONPATH=src
          python src/usdkrw_fetch.py

      - name: Cache VKOSPI (KRX)
        env:
          KRX_AUTH_KEY: ${{ secrets.KRX_AUTH_KEY }}
          KRX_DVRPROD_DD_TRD_URL: ${{ secrets.KRX_DVRPROD_DD_TRD_URL }}
        run: |
          set -e
          export PYTHONPATH=src
          python src/vkospi_fetch.py

      - name: Cache Put/Call (recent)
        env:
          KRX_AUTH_KEY: ${{ secrets.KRX_AUTH_KEY }}
          KRX_EQSOP_URL: ${{ secrets.KRX_EQSOP_URL }}
          KRX_EQKOP_URL: ${{ secrets.KRX_EQKOP_URL }}
          BACKFILL_START: ${{ env.BACKFILL_START }}
          BACKFILL_END: ${{ env.BACKFILL_END }}
          PUTCALL_CACHE_PATH: data/cache/putcall_ratio.parquet
        run: |
          set -e
          export PYTHONPATH=src
          python src/caches/cache_putcall.py

      - name: Sanity check caches exist
        run: |
          set -e
          ls -lah data/cache || true
          ls -lah data || true
          test -f data/cache/index_levels.parquet
          test -f data/cache/k200_close.parquet
          test -f data/cache/putcall_ratio.parquet
          test -f data/usdkrw_level.parquet
          test -f data/vkospi_level.parquet
          test -f data/cache/rates_3y_bundle.parquet

      # -------------------------
      # Factor 계산
      # -------------------------
      - name: Calculate Factors (F01,F04,F05,F06,F07,F08,F09,F10)
        env:
          ROLLING_DAYS: "1260"
          MIN_OBS: "252"
          VOL_WINDOW_DAYS: "20"
          K200_CACHE_PATH: data/cache/k200_close.parquet
          USDKRW_CACHE_PATH: data/usdkrw_level.parquet
          VKOSPI_CACHE_PATH: data/vkospi_level.parquet
          F08_CACHE_PATH: data/cache/f08_foreigner_flow.parquet
          PUTCALL_CACHE_PATH: data/cache/putcall_ratio.parquet
          RATES_3Y_BUNDLE_PATH: data/cache/rates_3y_bundle.parquet
          F07_HORIZON_DAYS: "20"
        run: |
          set -e
          export PYTHONPATH=src
          python src/factors/f01_momentum.py
          python src/factors/f04_putcall.py
          python src/factors/f05_credit_spread.py
          python src/factors/f06_vkospi.py
          python src/factors/f07_safehaven.py
          python src/factors/f08_foreigner_flow.py
          python src/factors/f09_margin_ratio.py
          python src/factors/f10_fxvol.py

      # -------------------------
      # Assemble (index_daily)
      # -------------------------
      - name: Assemble index (main)
        run: |
          set -e
          export PYTHONPATH=src
          python src/assemble/assemble_index.py

      # -------------------------
      # ✅ (C) 메인 ML(prob_up_10d) 생성 + index_daily에 merge
      # - "render_report.py" 실행 전에 index_daily.parquet에 prob_up_10d가 들어가야
      #   메인 리포트에서 ML이 '-'가 아니라 값으로 표시됨.
      # -------------------------
      - name: ML prob_up_10d (main, XGBoost, KOSPI, horizon=10)
        run: |
          set -e
          export PYTHONPATH=src
          python src/analysis/train_xgb_prob_up10.py
        env:
          FACTORS_DIR: data/factors
          INDEX_LEVELS_PATH: data/cache/index_levels.parquet
          TARGET_COL: kospi_close
          HORIZON_DAYS: "10"
          ADD_CONTRARIAN: "1"
          CONTRARIAN_SUFFIX: "_c"
          EXCLUDE_FACTORS: ""
          TAG: "main"
          OUT_PRED_PARQUET: data/analysis/prob_up_10d_main.parquet
          OUT_METRICS_CSV: data/analysis/ml_prob_up10_main_metrics.csv
          VKOSPI_LEVELS_PATH: data/vkospi_level.parquet
          F08_FLOW_PATH: data/cache/f08_foreigner_flow.parquet
          USDKRW_PATH: data/usdkrw_level.parquet
          ADD_USDKRW_RET20: "1"

      - name: Merge prob_up_10d into index_daily (main)
        run: |
          set -e
          export PYTHONPATH=src
          python src/analysis/merge_prob_into_index.py
        env:
          INDEX_PATH: data/index_daily.parquet
          CSV_PATH: data/index_daily.csv
          PROB_PATH: data/analysis/prob_up_10d_main.parquet

      # -------------------------
      # Report (docs/index.html)
      # -------------------------
      - name: Render report (main)
        run: |
          set -e
          export PYTHONPATH=src
          python src/report/render_report.py

      - name: Convert parquet to CSV (index_daily)
        run: |
          set -e
          export PYTHONPATH=src
          python src/parquet_to_csv.py

      - name: Commit & push outputs (rebase-safe)
        run: |
          set -euo pipefail
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"

          # ✅ 캐시/분석/지수/리포트 산출물 포함
          git add data/cache/index_levels.* || true
          git add data/cache/k200_close.* || true
          git add data/cache/*.parquet || true
          git add data/factors/ || true
          git add data/analysis/prob_up_10d_main.parquet data/analysis/ml_prob_up10_main_metrics.csv || true
          git add data/index_daily.* docs/index.html || true

          git diff --quiet && git diff --staged --quiet && exit 0

          git stash push -u -m "actions-stash-before-rebase" || true
          git fetch origin main
          git pull --rebase origin main
          git stash pop || true

          git add data/cache/index_levels.* || true
          git add data/cache/k200_close.* || true
          git add data/cache/*.parquet || true
          git add data/factors/ || true
          git add data/analysis/prob_up_10d_main.parquet data/analysis/ml_prob_up10_main_metrics.csv || true
          git add data/index_daily.* docs/index.html || true

          git diff --quiet && git diff --staged --quiet && exit 0

          git commit -m "Daily update $(date -u +%Y-%m-%d)" || true
          git push origin HEAD:main
