name: Stock Backfill (Full History)

on:
  workflow_dispatch:
    inputs:
      skip_prices:
        description: 'Skip price data fetch'
        type: boolean
        default: false
      skip_flows:
        description: 'Skip flows data fetch'
        type: boolean
        default: false
      skip_dart:
        description: 'Skip DART data fetch'
        type: boolean
        default: false
      clean_derived:
        description: 'Delete derived outputs (curated/analysis/docs) before curations'
        type: boolean
        default: true

jobs:
  backfill:
    runs-on: ubuntu-latest
    timeout-minutes: 330  # 5.5ì‹œê°„
    env:
      DART_API_KEY: ${{ secrets.DART_API_KEY }}
      SAMPLE_MODE: "false"
      MAX_WORKERS: "20"          # prices ë“± ê¸°ì¡´ ìœ ì§€
      MAX_WORKERS_FLOWS: "12"     # flows ì „ìš©
      INCREMENTAL_MODE: "false"
      START_DATE: "20150101"
      KRX_FLOWS_SAVE_FORMAT: "parquet"
      KRX_RETRY: "3"

      FLOW_INCLUDE_BUYSELL: "true"
      FLOW_INCLUDE_VOLUME: "true"
      FLOW_WINDOWS: "3,5,10,20"
      FLOW_RAW_FORMAT: "auto"
      KRX_NO_DATA_RETRY: "2"
      KRX_NO_DATA_SLEEP_BASE: "3.0"
      KRX_THROTTLE_SEC: "0.0"    # í•„ìš”í•˜ë©´ 0.1~0.3ìœ¼ë¡œ ì˜¬ë ¤ë³´ì„¸ìš”      

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install pandas pyarrow pykrx requests plotly

      - name: Init RUN TAG (for marker)
        run: |
          echo "RUN_TAG=${GITHUB_RUN_ID}_${GITHUB_RUN_ATTEMPT}" >> $GITHUB_ENV
          echo "RUN_TAG=$RUN_TAG"

      # âœ… ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰ (cd src/stocks ì œê±°)

      - name: "[1/11] Fetch listings (2771 stocks)"
        continue-on-error: true
        run: |
          python src/stocks/fetch_listings.py || echo "âš ï¸ ë§ˆìŠ¤í„° ëª©ë¡ ì˜¤ë¥˜"

      - name: "[2/11] Fetch prices (30~60ë¶„)"
        if: ${{ !inputs.skip_prices }}
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 30~60ë¶„ (ë³‘ë ¬ 20 workers)"
          python src/stocks/fetch_prices.py || echo "âš ï¸ ê°€ê²© ë°ì´í„° ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[3/11] Fetch KRX flows (60~90ë¶„)"
        if: ${{ !inputs.skip_flows }}
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 60~90ë¶„ (ë³‘ë ¬ 20 workers)"
          python src/stocks/fetch_krx_flows.py || echo "âš ï¸ ìˆ˜ê¸‰ ë°ì´í„° ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[3-1] Retry KRX flows (no data tickers only)"
        continue-on-error: true
        env:
          MAX_WORKERS_FLOWS_RETRY: "3"
          KRX_THROTTLE_SEC_RETRY2: "0.2"
          KRX_NO_DATA_RETRY_RETRY2: "3"
          KRX_NO_DATA_SLEEP_BASE_RETRY2: "5.0"
          RETRY2_OVERWRITE_IF_EXISTS: "false"
        run: |
          python src/stocks/fetch_krx_flows_retry_nodata.py || echo "âš ï¸ flows retry2 ì¼ë¶€ ì˜¤ë¥˜"
          
      - name: "[4/11] Fetch fundamentals (DIV/BPS/PER/EPS)"
        continue-on-error: true
        env:
          MAX_WORKERS_FUNDAMENTALS: "10"
          FUND_CHUNK_YEARS: "2"
          FUND_SAVE_FORMAT: "parquet"
          START_DATE: "20150101"
          END_DATE: "20261231"
        run: |
          python src/stocks/fetch_fundamentals.py || echo "âš ï¸ fundamentals ì¼ë¶€ ì˜¤ë¥˜"
      
      - name: "[4-1/11] Curate fundamentals"
        continue-on-error: true
        run: |
          python src/stocks/curate_fundamentals.py || echo "âš ï¸ fundamentals curate ì¼ë¶€ ì˜¤ë¥˜"
          
      

      - name: "[5/11] Fetch DART financials (30~60ë¶„)"
        if: ${{ !inputs.skip_dart }}
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 30~60ë¶„ (ë³‘ë ¬ 5 workers, DART API rate limit)"
          python src/stocks/fetch_dart_financials.py || echo "âš ï¸ DART ë°ì´í„° ì¼ë¶€ ì˜¤ë¥˜"

      # âœ… ì¤‘ê°„ ì €ìž¥ 1: Raw ë°ì´í„° ë°±ì—…
      - name: "[ì¤‘ê°„ ì €ìž¥ 1] Raw ë°ì´í„° ë°±ì—…"
        continue-on-error: true
        run: |
          echo "=== ì¤‘ê°„ ì €ìž¥ $(date) ==="
          du -sh data/stocks/ || true
          tar -czf raw_data_backup.tar.gz data/stocks/raw/ || true

      - name: "[ì¤‘ê°„ ì €ìž¥ 1-1] Raw ë°ì´í„° ì—…ë¡œë“œ"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: raw-data-backup
          path: raw_data_backup.tar.gz
          retention-days: 7
          if-no-files-found: warn

      # ============================================================
      # âœ… (NEW) derived outputs í´ë¦° ë¦¬ë¹Œë“œ + pre-clean ë°±ì—…
      # - ìœ„ì¹˜: raw ì—…ë¡œë“œ ì§í›„ / curate ì‹œìž‘ ì§ì „
      # ============================================================

      - name: "[í´ë¦°ì—…] Backup existing derived outputs (curated/analysis/docs)"
        if: ${{ inputs.clean_derived }}
        continue-on-error: true
        run: |
          echo "=== Pre-clean backup (derived outputs) ==="
          tar -czf pre_clean_derived_backup.tar.gz \
            data/stocks/curated \
            data/stocks/analysis \
            docs/stocks \
            2>/dev/null || true
          ls -lh pre_clean_derived_backup.tar.gz 2>/dev/null || true

      - name: "[í´ë¦°ì—…] Upload pre-clean backup artifact"
        if: ${{ always() && inputs.clean_derived }}
        uses: actions/upload-artifact@v4
        with:
          name: pre-clean-derived-backup
          path: pre_clean_derived_backup.tar.gz
          retention-days: 7
          if-no-files-found: warn

      - name: "[í´ë¦°ì—…] Remove derived outputs to rebuild cleanly"
        if: ${{ inputs.clean_derived }}
        run: |
          echo "=== Cleaning derived outputs ==="
          rm -rf data/stocks/curated || true
          rm -rf data/stocks/analysis || true
          rm -rf docs/stocks || true
          mkdir -p data/stocks/curated data/stocks/analysis docs/stocks
          echo "OK: derived outputs cleaned & directories recreated"

      # âœ… (NEW) Run marker: ì´ë²ˆ runì—ì„œ ìƒì„±ëœ ì‚°ì¶œë¬¼ì¸ì§€ íŒë³„
      - name: "[ë§ˆì»¤] Write run marker"
        if: always()
        run: |
          mkdir -p docs/stocks
          cat > docs/stocks/_run_marker.txt <<EOF
          run_tag=${RUN_TAG}
          run_id=${GITHUB_RUN_ID}
          run_attempt=${GITHUB_RUN_ATTEMPT}
          utc=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          EOF
          echo "=== marker ==="
          cat docs/stocks/_run_marker.txt

      - name: "[6/11] Curate financials"
        continue-on-error: true
        run: |
          python src/stocks/curate_financials.py || echo "âš ï¸ ìž¬ë¬´ íë ˆì´ì…˜ ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[7/11] Curate flows"
        continue-on-error: true
        run: |
          python src/stocks/curate_flows.py || echo "âš ï¸ ìˆ˜ê¸‰ íë ˆì´ì…˜ ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[8/11] Compute features"
        continue-on-error: true
        run: |
          python src/stocks/compute_features.py || echo "âš ï¸ Features ê³„ì‚° ì¼ë¶€ ì˜¤ë¥˜"

      - name: Export flows recent 60d CSV (Excel/ê²€ì¦ìš©)
        continue-on-error: true
        run: |
          export RECENT_DAYS=60
          python src/stocks/export_flows_recent60d_csv.py || echo "âš ï¸ flows_recent60d.csv ìƒì„± ì¼ë¶€ ì˜¤ë¥˜"

      - name: Upload flows recent 60d CSV
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flows-recent60d
          path: docs/stocks/flows_recent60d.csv
          if-no-files-found: warn

      # âœ… ì¤‘ê°„ ì €ìž¥ 2: Curated ë°ì´í„° ì»¤ë°‹ (ë¹ˆ ì»¤ë°‹ ë°©ì§€)
      - name: "[ì¤‘ê°„ ì €ìž¥ 2] Curated ë°ì´í„° ì»¤ë°‹"
        continue-on-error: true
        run: |
          CURATED_CNT=$(find data/stocks/curated -type f 2>/dev/null | wc -l | tr -d ' ')
          ANALYSIS_CNT=$(find data/stocks/analysis -type f 2>/dev/null | wc -l | tr -d ' ')
          echo "curated files: $CURATED_CNT, analysis files: $ANALYSIS_CNT"
          if [ "$CURATED_CNT" = "0" ] && [ "$ANALYSIS_CNT" = "0" ]; then
            echo "âš ï¸ curated/analysis empty -> skip commit"
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/stocks/master/ || true
          git add data/stocks/curated/ || true
          git add data/stocks/analysis/ || true

          git diff --staged --quiet || \
            git commit -m "Backfill WIP: curated data ($(date +%Y%m%d_%H%M))" || true

          git push || echo "âš ï¸ Git push ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)"

      - name: "[9/11] Render reports (2771 stocks)"
        continue-on-error: true
        run: |
          python src/stocks/render_stock_report.py || echo "âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[10/11] Export CSV summaries"
        continue-on-error: true
        run: |
          python src/stocks/export_data_summary.py || echo "âš ï¸ CSV ì¶œë ¥ ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[11/11] Export raw data to CSV"
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 5~10ë¶„ (ëŒ€ìš©ëŸ‰ CSV ìƒì„±)"
          python src/stocks/export_raw_to_csv.py || echo "âš ï¸ Raw CSV ì¶œë ¥ ì¼ë¶€ ì˜¤ë¥˜"

      # ============================================================
      # âœ… (NEW) Output verification
      # - index.htmlë§Œ ë‚¨ì€ "ê°€ì§œ ì„±ê³µ" ë°©ì§€
      # - markerê°€ ì´ë²ˆ RUN_TAGì¸ì§€ í™•ì¸
      # - ì´í›„ ì—…ë¡œë“œ stepë“¤ì„ ì¡°ê±´ë¶€ë¡œ ì‹¤í–‰
      # ============================================================

      - name: "Verify outputs (prevent stale artifacts)"
        if: always()
        id: verify_outputs
        run: |
          set +e

          echo "=== Verify outputs ==="
          echo "RUN_TAG=$RUN_TAG"

          MARKER_OK="false"
          if [ -f "docs/stocks/_run_marker.txt" ]; then
            cat docs/stocks/_run_marker.txt
            grep -q "run_tag=${RUN_TAG}" docs/stocks/_run_marker.txt && MARKER_OK="true"
          fi

          HTML_TOTAL=$(ls docs/stocks/*.html 2>/dev/null | wc -l | tr -d ' ')
          HTML_NON_INDEX=$(ls docs/stocks/*.html 2>/dev/null | grep -v "index.html" | wc -l | tr -d ' ')
          CSV_TOTAL=$(ls docs/stocks/*.csv 2>/dev/null | wc -l | tr -d ' ')

          INDEX_EXISTS="false"
          [ -f "docs/stocks/index.html" ] && INDEX_EXISTS="true"

          echo "MARKER_OK=$MARKER_OK"
          echo "INDEX_EXISTS=$INDEX_EXISTS"
          echo "HTML_TOTAL=$HTML_TOTAL"
          echo "HTML_NON_INDEX=$HTML_NON_INDEX"
          echo "CSV_TOTAL=$CSV_TOTAL"

          HAS_HTML="false"
          if [ "$MARKER_OK" = "true" ] && [ "$HTML_NON_INDEX" -ge 1 ]; then
            HAS_HTML="true"
          fi

          HAS_CSV="false"
          if [ "$MARKER_OK" = "true" ] && [ "$CSV_TOTAL" -ge 1 ]; then
            HAS_CSV="true"
          fi

          HAS_MASTER_SUMMARY="false"
          [ -f "docs/stocks/master_summary.csv" ] && HAS_MASTER_SUMMARY="true"

          HAS_RAW_CSV="false"
          if [ -f "docs/stocks/prices_raw.csv" ] || [ -f "docs/stocks/flows_raw.csv" ] || [ -f "docs/stocks/financials_raw.csv" ]; then
            HAS_RAW_CSV="true"
          fi

          echo "has_html=$HAS_HTML" >> $GITHUB_OUTPUT
          echo "has_csv=$HAS_CSV" >> $GITHUB_OUTPUT
          echo "has_master_summary=$HAS_MASTER_SUMMARY" >> $GITHUB_OUTPUT
          echo "has_raw_csv=$HAS_RAW_CSV" >> $GITHUB_OUTPUT
          echo "html_total=$HTML_TOTAL" >> $GITHUB_OUTPUT
          echo "html_non_index=$HTML_NON_INDEX" >> $GITHUB_OUTPUT
          echo "csv_total=$CSV_TOTAL" >> $GITHUB_OUTPUT

      - name: "Check results (always print)"
        if: always()
        run: |
          echo "=== ìµœì¢… ê²°ê³¼ ==="
          echo "RUN_TAG=$RUN_TAG"
          echo "verify.has_html=${{ steps.verify_outputs.outputs.has_html }}"
          echo "verify.has_csv=${{ steps.verify_outputs.outputs.has_csv }}"
          echo "verify.html_non_index=${{ steps.verify_outputs.outputs.html_non_index }}"
          echo "verify.csv_total=${{ steps.verify_outputs.outputs.csv_total }}"

          echo ""
          echo "ë°ì´í„° ìš©ëŸ‰:"
          du -sh data/stocks/ 2>/dev/null || echo "data ì—†ìŒ"
          du -sh docs/stocks/ 2>/dev/null || echo "docs ì—†ìŒ"

          echo ""
          echo "docs/stocks ìƒìœ„ ëª©ë¡:"
          ls -lh docs/stocks/ 2>/dev/null | head -30 || true

          echo ""
          echo "ì¢…ëª© ìˆ˜ í†µê³„:"
          echo "  ê°€ê²©: $(ls data/stocks/raw/prices/ 2>/dev/null | wc -l)"
          echo "  ìˆ˜ê¸‰: $(ls data/stocks/raw/krx_flows/ 2>/dev/null | wc -l)"
          echo "  DART: $(ls data/stocks/raw/dart/ 2>/dev/null | wc -l)"
          echo "  HTML: $(ls docs/stocks/*.html 2>/dev/null | wc -l)"
          echo "  CSV: $(ls docs/stocks/*.csv 2>/dev/null | wc -l)"

      # âœ… Artifacts ì—…ë¡œë“œ (ì¡°ê±´ë¶€)

      - name: "Prepare HTML upload (ìƒ˜í”Œ 100ê°œ)"
        if: ${{ always() && steps.verify_outputs.outputs.has_html == 'true' }}
        run: |
          mkdir -p upload_html
          # index í¬í•¨ + ê°œë³„ html 100ê°œ
          cp docs/stocks/index.html upload_html/ 2>/dev/null || true
          ls docs/stocks/*.html 2>/dev/null | grep -v "index.html" | head -100 | xargs -I {} cp {} upload_html/ || true
          cp docs/stocks/_run_marker.txt upload_html/ 2>/dev/null || true

      - name: "Upload HTML artifact"
        if: ${{ always() && steps.verify_outputs.outputs.has_html == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: backfill-html-sample
          path: upload_html/
          retention-days: 30
          if-no-files-found: warn

      - name: "Upload CSV reports"
        if: ${{ always() && steps.verify_outputs.outputs.has_csv == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: backfill-csv-reports
          path: docs/stocks/*.csv
          retention-days: 90
          if-no-files-found: warn

      - name: "Upload raw data CSVs"
        if: ${{ always() && steps.verify_outputs.outputs.has_raw_csv == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: raw-data-csvs
          path: |
            docs/stocks/prices_raw.csv
            docs/stocks/flows_raw.csv
            docs/stocks/financials_raw.csv
          retention-days: 30
          if-no-files-found: warn

      - name: "Upload master summary"
        if: ${{ always() && steps.verify_outputs.outputs.has_master_summary == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: master-summary
          path: docs/stocks/master_summary.csv
          retention-days: 90
          if-no-files-found: warn

      # âœ… ìµœì¢… ì»¤ë°‹ (ë¹ˆ ì»¤ë°‹ ë°©ì§€)

      - name: "Final commit (curated + reports)"
        if: always()
        continue-on-error: true
        run: |
          CURATED_CNT=$(find data/stocks/curated -type f 2>/dev/null | wc -l | tr -d ' ')
          ANALYSIS_CNT=$(find data/stocks/analysis -type f 2>/dev/null | wc -l | tr -d ' ')
          DOCS_CNT=$(find docs/stocks -type f 2>/dev/null | wc -l | tr -d ' ')
          echo "curated files: $CURATED_CNT, analysis files: $ANALYSIS_CNT, docs files: $DOCS_CNT"
          if [ "$CURATED_CNT" = "0" ] && [ "$ANALYSIS_CNT" = "0" ] && [ "$DOCS_CNT" = "0" ]; then
            echo "âš ï¸ derived outputs empty -> skip final commit"
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/stocks/master/ || true
          git add data/stocks/curated/ || true
          git add data/stocks/analysis/ || true
          git add docs/stocks/*.csv || true
          git add docs/stocks/index.html || true

          git diff --staged --quiet || \
            git commit -m "Backfill complete: curated data + reports ($(date +%Y%m%d))" || true

          git push || echo "âš ï¸ Final push ì‹¤íŒ¨"

      # âœ… ë°±í•„ ìš”ì•½ ë¦¬í¬íŠ¸

      - name: "Generate backfill summary"
        if: always()
        run: |
          cat > backfill_summary.txt <<EOF
          ===================================
          ë°±í•„ ì™„ë£Œ ë¦¬í¬íŠ¸
          ===================================
          ì™„ë£Œ ì‹œê°„: $(date)
          RUN_TAG: ${RUN_TAG}

          ðŸ“Š ë°ì´í„° í†µê³„:
          - ê°€ê²© ë°ì´í„°: $(ls data/stocks/raw/prices/ 2>/dev/null | wc -l) ì¢…ëª©
          - ìˆ˜ê¸‰ ë°ì´í„°: $(ls data/stocks/raw/krx_flows/ 2>/dev/null | wc -l) ì¢…ëª©
          - DART ë°ì´í„°: $(ls data/stocks/raw/dart/ 2>/dev/null | wc -l) ì¢…ëª©
          - Features: $(ls data/stocks/analysis/ 2>/dev/null | wc -l) ì¢…ëª©
          - HTML ë¦¬í¬íŠ¸: $(ls docs/stocks/*.html 2>/dev/null | wc -l) ê°œ
          - CSV íŒŒì¼: $(ls docs/stocks/*.csv 2>/dev/null | wc -l) ê°œ

          âœ… Verify:
          - has_html: ${{ steps.verify_outputs.outputs.has_html }}
          - html_non_index: ${{ steps.verify_outputs.outputs.html_non_index }}
          - has_csv: ${{ steps.verify_outputs.outputs.has_csv }}
          - csv_total: ${{ steps.verify_outputs.outputs.csv_total }}

          ðŸ’¾ ë””ë ‰í† ë¦¬ ìš©ëŸ‰:
          $(du -sh data/stocks/raw/ 2>/dev/null || echo "raw: N/A")
          $(du -sh data/stocks/curated/ 2>/dev/null || echo "curated: N/A")
          $(du -sh data/stocks/analysis/ 2>/dev/null || echo "analysis: N/A")
          $(du -sh docs/stocks/ 2>/dev/null || echo "docs: N/A")

          ðŸ“ˆ ì™„ë£Œìœ¨:
          $(python3 -c "
          import pandas as pd
          try:
              df = pd.read_csv('docs/stocks/master_summary.csv')
              complete = (df['has_features']==True).sum()
              total = len(df)
              print(f'ë°ì´í„° ì™„ë£Œ: {complete}/{total} ({complete/total*100:.1f}%)')
          except Exception as e:
              print('ì™„ë£Œìœ¨ ê³„ì‚° ë¶ˆê°€', e)
          " 2>/dev/null || echo "ì™„ë£Œìœ¨: N/A")

          ===================================
          EOF

          cat backfill_summary.txt

      - name: "Upload backfill summary"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backfill-summary
          path: backfill_summary.txt
          retention-days: 90
          if-no-files-found: warn
