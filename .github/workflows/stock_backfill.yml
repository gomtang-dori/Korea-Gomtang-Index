name: Stock Backfill (Full History)

on:
  workflow_dispatch:
    inputs:
      skip_prices:
        description: 'Skip price data fetch'
        type: boolean
        default: false
      skip_flows:
        description: 'Skip flows data fetch'
        type: boolean
        default: false
      skip_dart:
        description: 'Skip DART data fetch'
        type: boolean
        default: false
      clean_derived:
        description: 'Delete derived outputs (curated/analysis/docs) before curations'
        type: boolean
        default: true

jobs:
  backfill:
    runs-on: ubuntu-latest
    timeout-minutes: 330  # 5.5ì‹œê°„
    env:
      DART_API_KEY: ${{ secrets.DART_API_KEY }}
      SAMPLE_MODE: "false"

      # pricesëŠ” 20 ìœ ì§€
      MAX_WORKERS: "20"

      # flowsëŠ” ë³„ë„(ì•ˆì •ì„±) - 6 ê¶Œìž¥
      MAX_WORKERS_FLOWS: "6"

      INCREMENTAL_MODE: "false"
      START_DATE: "20150101"

      # KRX flows raw ì €ìž¥
      KRX_FLOWS_SAVE_FORMAT: "parquet"
      KRX_RETRY: "3"
      KRX_NO_DATA_RETRY: "2"
      KRX_NO_DATA_SLEEP_BASE: "3.0"
      KRX_THROTTLE_SEC: "0.0"    # í•„ìš”ì‹œ 0.1~0.3

      # curate flows ì˜µì…˜
      FLOW_INCLUDE_BUYSELL: "true"
      FLOW_INCLUDE_VOLUME: "true"
      FLOW_WINDOWS: "3,5,10,20"
      FLOW_RAW_FORMAT: "auto"

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install pandas pyarrow pykrx requests plotly

      - name: Init RUN TAG (for marker)
        run: |
          echo "RUN_TAG=${GITHUB_RUN_ID}_${GITHUB_RUN_ATTEMPT}" >> $GITHUB_ENV
          echo "RUN_TAG=$RUN_TAG"

      # ============================================================
      # âœ… clean_derived ëŠ” "ëª¨ë“  curate/compute/render/export" ë³´ë‹¤ ë¨¼ì €!
      # ============================================================

      - name: "[í´ë¦°ì—…] Backup existing derived outputs (curated/analysis/docs)"
        if: ${{ inputs.clean_derived }}
        continue-on-error: true
        run: |
          echo "=== Pre-clean backup (derived outputs) ==="
          tar -czf pre_clean_derived_backup.tar.gz \
            data/stocks/curated \
            data/stocks/analysis \
            docs/stocks \
            2>/dev/null || true
          ls -lh pre_clean_derived_backup.tar.gz 2>/dev/null || true

      - name: "[í´ë¦°ì—…] Upload pre-clean backup artifact"
        if: ${{ always() && inputs.clean_derived }}
        uses: actions/upload-artifact@v4
        with:
          name: pre-clean-derived-backup
          path: pre_clean_derived_backup.tar.gz
          retention-days: 7
          if-no-files-found: warn

      - name: "[í´ë¦°ì—…] Remove derived outputs to rebuild cleanly"
        if: ${{ inputs.clean_derived }}
        run: |
          echo "=== Cleaning derived outputs ==="
          rm -rf data/stocks/curated || true
          rm -rf data/stocks/analysis || true
          rm -rf docs/stocks || true
          mkdir -p data/stocks/curated data/stocks/analysis docs/stocks
          echo "OK: derived outputs cleaned & directories recreated"

      - name: "[ë§ˆì»¤] Write run marker"
        if: always()
        run: |
          mkdir -p docs/stocks
          cat > docs/stocks/_run_marker.txt <<EOF
          run_tag=${RUN_TAG}
          run_id=${GITHUB_RUN_ID}
          run_attempt=${GITHUB_RUN_ATTEMPT}
          utc=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          EOF
          echo "=== marker ==="
          cat docs/stocks/_run_marker.txt

      # ============================================================
      # âœ… Fetch ë‹¨ê³„ (raw ìƒì„±/ê°±ì‹ )
      # ============================================================

      - name: "[1/12] Fetch listings (2771 stocks)"
        continue-on-error: true
        run: |
          python src/stocks/fetch_listings.py || echo "âš ï¸ ë§ˆìŠ¤í„° ëª©ë¡ ì˜¤ë¥˜"

      - name: "[2/12] Fetch prices (30~60ë¶„)"
        if: ${{ !inputs.skip_prices }}
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 30~60ë¶„ (ë³‘ë ¬ 20 workers)"
          python src/stocks/fetch_prices.py || echo "âš ï¸ ê°€ê²© ë°ì´í„° ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[3/12] Fetch KRX flows (60~90ë¶„)"
        if: ${{ !inputs.skip_flows }}
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 60~90ë¶„ (flows workers=${MAX_WORKERS_FLOWS})"
          python src/stocks/fetch_krx_flows.py || echo "âš ï¸ ìˆ˜ê¸‰ ë°ì´í„° ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[3-1/12] Retry KRX flows (no data tickers only)"
        if: ${{ !inputs.skip_flows }}
        continue-on-error: true
        env:
          MAX_WORKERS_FLOWS_RETRY: "3"
          KRX_THROTTLE_SEC_RETRY2: "0.2"
          KRX_NO_DATA_RETRY_RETRY2: "3"
          KRX_NO_DATA_SLEEP_BASE_RETRY2: "5.0"
          RETRY2_OVERWRITE_IF_EXISTS: "false"
        run: |
          python src/stocks/fetch_krx_flows_retry_nodata.py || echo "âš ï¸ flows retry2 ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[4/12] Fetch fundamentals (DIV/BPS/PER/EPS)"
        continue-on-error: true
        env:
          MAX_WORKERS_FUNDAMENTALS: "10"
          FUND_CHUNK_YEARS: "2"
          FUND_SAVE_FORMAT: "parquet"
          START_DATE: "20150101"
          END_DATE: "20261231"
        run: |
          python src/stocks/fetch_fundamentals.py || echo "âš ï¸ fundamentals ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[5/12] Fetch DART financials (30~60ë¶„)"
        if: ${{ !inputs.skip_dart }}
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 30~60ë¶„ (ë³‘ë ¬ 5 workers, DART API rate limit)"
          python src/stocks/fetch_dart_financials.py || echo "âš ï¸ DART ë°ì´í„° ì¼ë¶€ ì˜¤ë¥˜"

      # âœ… ì¤‘ê°„ ì €ìž¥ 1: Raw ë°ì´í„° ë°±ì—…
      - name: "[ì¤‘ê°„ ì €ìž¥ 1] Raw ë°ì´í„° ë°±ì—…"
        continue-on-error: true
        run: |
          echo "=== raw backup $(date) ==="
          du -sh data/stocks/ || true
          tar -czf raw_data_backup.tar.gz data/stocks/raw/ || true

      - name: "[ì¤‘ê°„ ì €ìž¥ 1-1] Raw ë°ì´í„° ì—…ë¡œë“œ"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: raw-data-backup
          path: raw_data_backup.tar.gz
          retention-days: 7
          if-no-files-found: warn

      # ============================================================
      # âœ… Curate ë‹¨ê³„ (derived ìƒì„±) - clean ì´í›„ì—ë§Œ ì‹¤í–‰
      # ============================================================

      - name: "[6/12] Curate financials"
        continue-on-error: true
        run: |
          python src/stocks/curate_financials.py || echo "âš ï¸ ìž¬ë¬´ íë ˆì´ì…˜ ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[7/12] Curate flows"
        continue-on-error: true
        run: |
          python src/stocks/curate_flows.py || echo "âš ï¸ ìˆ˜ê¸‰ íë ˆì´ì…˜ ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[8/12] Curate fundamentals"
        continue-on-error: true
        run: |
          python src/stocks/curate_fundamentals.py || echo "âš ï¸ fundamentals curate ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[9/12] Compute features"
        continue-on-error: true
        run: |
          python src/stocks/compute_features.py || echo "âš ï¸ Features ê³„ì‚° ì¼ë¶€ ì˜¤ë¥˜"

      - name: "Export flows recent 60d CSV (Excel/ê²€ì¦ìš©)"
        continue-on-error: true
        run: |
          export RECENT_DAYS=60
          python src/stocks/export_flows_recent60d_csv.py || echo "âš ï¸ flows_recent60d.csv ìƒì„± ì¼ë¶€ ì˜¤ë¥˜"

      - name: "Upload flows recent 60d CSV"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flows-recent60d
          path: docs/stocks/flows_recent60d.csv
          if-no-files-found: warn

      # âœ… ì¤‘ê°„ ì €ìž¥ 2: Curated ë°ì´í„° ì»¤ë°‹ (ë¹ˆ ì»¤ë°‹ ë°©ì§€)
      - name: "[ì¤‘ê°„ ì €ìž¥ 2] Curated ë°ì´í„° ì»¤ë°‹"
        continue-on-error: true
        run: |
          CURATED_CNT=$(find data/stocks/curated -type f 2>/dev/null | wc -l | tr -d ' ')
          ANALYSIS_CNT=$(find data/stocks/analysis -type f 2>/dev/null | wc -l | tr -d ' ')
          echo "curated files: $CURATED_CNT, analysis files: $ANALYSIS_CNT"
          if [ "$CURATED_CNT" = "0" ] && [ "$ANALYSIS_CNT" = "0" ]; then
            echo "âš ï¸ curated/analysis empty -> skip commit"
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/stocks/master/ || true
          git add data/stocks/curated/ || true
          git add data/stocks/analysis/ || true

          git diff --staged --quiet || \
            git commit -m "Backfill WIP: curated data ($(date +%Y%m%d_%H%M))" || true

          git push || echo "âš ï¸ Git push ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)"

      - name: "[10/12] Render reports (2771 stocks)"
        continue-on-error: true
        run: |
          python src/stocks/render_stock_report.py || echo "âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[11/12] Export CSV summaries"
        continue-on-error: true
        run: |
          python src/stocks/export_data_summary.py || echo "âš ï¸ CSV ì¶œë ¥ ì¼ë¶€ ì˜¤ë¥˜"

      - name: "[12/12] Export raw data to CSV"
        continue-on-error: true
        run: |
          echo "â±ï¸  ì˜ˆìƒ ì†Œìš”: 5~10ë¶„ (ëŒ€ìš©ëŸ‰ CSV ìƒì„±)"
          python src/stocks/export_raw_to_csv.py || echo "âš ï¸ Raw CSV ì¶œë ¥ ì¼ë¶€ ì˜¤ë¥˜"

      # ============================================================
      # âœ… Output verification / artifact / final commit / summary
      # ============================================================

      - name: "Verify outputs (prevent stale artifacts)"
        if: always()
        id: verify_outputs
        run: |
          set +e

          echo "=== Verify outputs ==="
          echo "RUN_TAG=$RUN_TAG"

          MARKER_OK="false"
          if [ -f "docs/stocks/_run_marker.txt" ]; then
            cat docs/stocks/_run_marker.txt
            grep -q "run_tag=${RUN_TAG}" docs/stocks/_run_marker.txt && MARKER_OK="true"
          fi

          HTML_TOTAL=$(ls docs/stocks/*.html 2>/dev/null | wc -l | tr -d ' ')
          HTML_NON_INDEX=$(ls docs/stocks/*.html 2>/dev/null | grep -v "index.html" | wc -l | tr -d ' ')
          CSV_TOTAL=$(ls docs/stocks/*.csv 2>/dev/null | wc -l | tr -d ' ')

          HAS_HTML="false"
          if [ "$MARKER_OK" = "true" ] && [ "$HTML_NON_INDEX" -ge 1 ]; then
            HAS_HTML="true"
          fi

          HAS_CSV="false"
          if [ "$MARKER_OK" = "true" ] && [ "$CSV_TOTAL" -ge 1 ]; then
            HAS_CSV="true"
          fi

          HAS_MASTER_SUMMARY="false"
          [ -f "docs/stocks/master_summary.csv" ] && HAS_MASTER_SUMMARY="true"

          HAS_RAW_CSV="false"
          if [ -f "docs/stocks/prices_raw.csv" ] || [ -f "docs/stocks/flows_raw.csv" ] || [ -f "docs/stocks/financials_raw.csv" ]; then
            HAS_RAW_CSV="true"
          fi

          echo "has_html=$HAS_HTML" >> $GITHUB_OUTPUT
          echo "has_csv=$HAS_CSV" >> $GITHUB_OUTPUT
          echo "has_master_summary=$HAS_MASTER_SUMMARY" >> $GITHUB_OUTPUT
          echo "has_raw_csv=$HAS_RAW_CSV" >> $GITHUB_OUTPUT
          echo "html_total=$HTML_TOTAL" >> $GITHUB_OUTPUT
          echo "html_non_index=$HTML_NON_INDEX" >> $GITHUB_OUTPUT
          echo "csv_total=$CSV_TOTAL" >> $GITHUB_OUTPUT

      - name: "Check results (always print)"
        if: always()
        run: |
          echo "=== ìµœì¢… ê²°ê³¼ ==="
          echo "RUN_TAG=$RUN_TAG"
          echo "verify.has_html=${{ steps.verify_outputs.outputs.has_html }}"
          echo "verify.has_csv=${{ steps.verify_outputs.outputs.has_csv }}"
          echo "verify.html_non_index=${{ steps.verify_outputs.outputs.html_non_index }}"
          echo "verify.csv_total=${{ steps.verify_outputs.outputs.csv_total }}"

          echo ""
          echo "ë””ë ‰í† ë¦¬ ìš©ëŸ‰:"
          du -sh data/stocks/ 2>/dev/null || echo "data ì—†ìŒ"
          du -sh docs/stocks/ 2>/dev/null || echo "docs ì—†ìŒ"

          echo ""
          echo "ì¢…ëª© ìˆ˜ í†µê³„:"
          echo "  ê°€ê²©: $(ls data/stocks/raw/prices/ 2>/dev/null | wc -l)"
          echo "  ìˆ˜ê¸‰: $(ls data/stocks/raw/krx_flows/ 2>/dev/null | wc -l)"
          echo "  fundamentals(raw): $(ls data/stocks/raw/fundamentals/ 2>/dev/null | wc -l)"
          echo "  fundamentals(curated): $(find data/stocks/curated -name fundamentals_daily.parquet 2>/dev/null | wc -l)"
          echo "  HTML: $(ls docs/stocks/*.html 2>/dev/null | wc -l)"
          echo "  CSV: $(ls docs/stocks/*.csv 2>/dev/null | wc -l)"

      - name: "Prepare HTML upload (ìƒ˜í”Œ 100ê°œ)"
        if: ${{ always() && steps.verify_outputs.outputs.has_html == 'true' }}
        run: |
          mkdir -p upload_html
          cp docs/stocks/index.html upload_html/ 2>/dev/null || true
          ls docs/stocks/*.html 2>/dev/null | grep -v "index.html" | head -100 | xargs -I {} cp {} upload_html/ || true
          cp docs/stocks/_run_marker.txt upload_html/ 2>/dev/null || true

      - name: "Upload HTML artifact"
        if: ${{ always() && steps.verify_outputs.outputs.has_html == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: backfill-html-sample
          path: upload_html/
          retention-days: 30
          if-no-files-found: warn

      - name: "Upload CSV reports"
        if: ${{ always() && steps.verify_outputs.outputs.has_csv == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: backfill-csv-reports
          path: docs/stocks/*.csv
          retention-days: 90
          if-no-files-found: warn

      - name: "Upload raw data CSVs"
        if: ${{ always() && steps.verify_outputs.outputs.has_raw_csv == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: raw-data-csvs
          path: |
            docs/stocks/prices_raw.csv
            docs/stocks/flows_raw.csv
            docs/stocks/financials_raw.csv
          retention-days: 30
          if-no-files-found: warn

      - name: "Upload master summary"
        if: ${{ always() && steps.verify_outputs.outputs.has_master_summary == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: master-summary
          path: docs/stocks/master_summary.csv
          retention-days: 90
          if-no-files-found: warn

      - name: "Final commit (curated + reports)"
        if: always()
        continue-on-error: true
        run: |
          CURATED_CNT=$(find data/stocks/curated -type f 2>/dev/null | wc -l | tr -d ' ')
          ANALYSIS_CNT=$(find data/stocks/analysis -type f 2>/dev/null | wc -l | tr -d ' ')
          DOCS_CNT=$(find docs/stocks -type f 2>/dev/null | wc -l | tr -d ' ')
          echo "curated files: $CURATED_CNT, analysis files: $ANALYSIS_CNT, docs files: $DOCS_CNT"
          if [ "$CURATED_CNT" = "0" ] && [ "$ANALYSIS_CNT" = "0" ] && [ "$DOCS_CNT" = "0" ]; then
            echo "âš ï¸ derived outputs empty -> skip final commit"
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/stocks/master/ || true
          git add data/stocks/curated/ || true
          git add data/stocks/analysis/ || true
          git add docs/stocks/*.csv || true
          git add docs/stocks/index.html || true

          git diff --staged --quiet || \
            git commit -m "Backfill complete: curated data + reports ($(date +%Y%m%d))" || true

          git push || echo "âš ï¸ Final push ì‹¤íŒ¨"

      - name: "Generate backfill summary"
        if: always()
        run: |
          cat > backfill_summary.txt <<EOF
          ===================================
          ë°±í•„ ì™„ë£Œ ë¦¬í¬íŠ¸
          ===================================
          ì™„ë£Œ ì‹œê°„: $(date)
          RUN_TAG: ${RUN_TAG}

          ðŸ“Š ë°ì´í„° í†µê³„:
          - ê°€ê²© ë°ì´í„°: $(ls data/stocks/raw/prices/ 2>/dev/null | wc -l) ì¢…ëª©
          - ìˆ˜ê¸‰ ë°ì´í„°: $(ls data/stocks/raw/krx_flows/ 2>/dev/null | wc -l) ì¢…ëª©
          - fundamentals(raw): $(ls data/stocks/raw/fundamentals/ 2>/dev/null | wc -l) ì¢…ëª©
          - fundamentals(curated): $(find data/stocks/curated -name fundamentals_daily.parquet 2>/dev/null | wc -l) ì¢…ëª©
          - DART ë°ì´í„°: $(ls data/stocks/raw/dart/ 2>/dev/null | wc -l) ì¢…ëª©
          - Features: $(ls data/stocks/analysis/ 2>/dev/null | wc -l) ì¢…ëª©
          - HTML ë¦¬í¬íŠ¸: $(ls docs/stocks/*.html 2>/dev/null | wc -l) ê°œ
          - CSV íŒŒì¼: $(ls docs/stocks/*.csv 2>/dev/null | wc -l) ê°œ

          âœ… Verify:
          - has_html: ${{ steps.verify_outputs.outputs.has_html }}
          - html_non_index: ${{ steps.verify_outputs.outputs.html_non_index }}
          - has_csv: ${{ steps.verify_outputs.outputs.has_csv }}
          - csv_total: ${{ steps.verify_outputs.outputs.csv_total }}

          ðŸ’¾ ë””ë ‰í† ë¦¬ ìš©ëŸ‰:
          $(du -sh data/stocks/raw/ 2>/dev/null || echo "raw: N/A")
          $(du -sh data/stocks/curated/ 2>/dev/null || echo "curated: N/A")
          $(du -sh data/stocks/analysis/ 2>/dev/null || echo "analysis: N/A")
          $(du -sh docs/stocks/ 2>/dev/null || echo "docs: N/A")
          EOF

          cat backfill_summary.txt

      - name: "Upload backfill summary"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backfill-summary
          path: backfill_summary.txt
          retention-days: 90
          if-no-files-found: warn
